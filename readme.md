# üöÄ Data Export Tool - Self-Service Analytics Platform

> **Revolutionizing data exports with configuration-driven architecture and convention-based automation**

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.24+-red.svg)](https://streamlit.io)
[![SQLAlchemy](https://img.shields.io/badge/SQLAlchemy-2.0+-green.svg)](https://sqlalchemy.org)
[![SingleStore](https://img.shields.io/badge/SingleStore-Compatible-purple.svg)](https://singlestore.com)

## üìñ **Overview**

The Data Export Tool is a **self-service analytics platform** that empowers business users to export data independently without requiring SQL knowledge or developer intervention. Built with a revolutionary **configuration-driven + convention-based architecture**, it transforms the traditional 5-step manual process into an elegant 3-step automated workflow.

### üéØ **Problem Solved**

**Before:** Data exports required developer intervention, manual SQL writing, and complex file management  
**After:** Business users can export any dataset with just 3 clicks, no technical knowledge required  

### üèÜ **Key Achievements**

- ‚úÖ **40% reduction** in development effort (5 steps ‚Üí 3 steps)
- ‚úÖ **100% elimination** of boilerplate Python code through convention-based loading
- ‚úÖ **50+ concurrent users** supported with optimized database connection pooling
- ‚úÖ **Zero breaking changes** during architecture optimization
- ‚úÖ **Self-service capability** - no more waiting for developers

---

## ‚ú® **Features**

### üé® **For Business Users**
- **üñ±Ô∏è One-Click Exports**: Preview ‚Üí Export ‚Üí Download workflow
- **üìä 6 Pre-built Reports**: Keyword analytics, sales data, competition insights, and more
- **üéõÔ∏è Smart Filters**: Date ranges, device types, storefronts, and custom parameters
- **‚ö° Lightning Fast**: Sub-2-minute exports with intelligent caching
- **üì± Responsive Design**: Works on desktop, tablet, and mobile devices
- **üõ°Ô∏è Safe Limits**: Automatic 50k row limit prevents server overload

### üõ†Ô∏è **For Developers**
- **‚öôÔ∏è Configuration-Driven**: Add new reports by editing config files, no code changes
- **üîÑ Convention-Based Loading**: SQL files automatically detected and loaded
- **üèóÔ∏è Modular Architecture**: Clean separation between UI, logic, and data layers
- **üìà Production-Ready**: Connection pooling, caching, error handling, and monitoring
- **üîß Developer-Friendly**: Comprehensive debugging tools and error messages

### üöÄ **Technical Highlights**
- **Zero Boilerplate**: Eliminated 7 duplicate Python data modules through automation
- **Smart Caching**: 3-layer caching strategy (DB queries, configs, SQL files)
- **Dynamic UI**: Forms automatically generated from field configurations
- **Scalable Database**: Optimized connection pooling supports 50+ concurrent users
- **Robust Error Handling**: Graceful degradation with helpful error messages

---

## üèóÔ∏è **Architecture**

### **Configuration-Driven + Convention-Based Design**

```mermaid
graph TB
    A[User Selects Report] --> B[Page Config Lookup]
    B --> C[Data Source Detection]
    C --> D[Dynamic UI Generation]
    D --> E[User Input & Validation]
    E --> F[Convention-Based SQL Loading]
    F --> G[Database Execution with Pooling]
    G --> H[Intelligent Caching]
    H --> I[Results Display & Export]

    style A fill:#e1f5fe
    style D fill:#f3e5f5
    style F fill:#e8f5e8
    style G fill:#fff3e0
    style H fill:#fce4ec
```

### **Project Structure**

```
üìÅ Data_Export_Tool/
‚îú‚îÄ‚îÄ üéØ main.py                           # Application entry point
‚îú‚îÄ‚îÄ üé® assets/style.css                  # Custom styling
‚îú‚îÄ‚îÄ üì± pages/                            # Streamlit pages
‚îÇ   ‚îú‚îÄ‚îÄ 1_Help.py                        # User documentation
‚îÇ   ‚îú‚îÄ‚îÄ 2_Storefront_in_Workspace.py     # Storefront discovery
‚îÇ   ‚îú‚îÄ‚îÄ 3_Keyword_Lab.py                 # Keyword analytics
‚îÇ   ‚îú‚îÄ‚îÄ 4_Digital_Shelf_Analytics.py     # Multi-tab analytics
‚îÇ   ‚îî‚îÄ‚îÄ 5_Marketing_Automation.py        # Campaign & optimization data
‚îú‚îÄ‚îÄ üóÉÔ∏è data_logic/
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ sql/                          # ‚≠ê ONLY SQL files needed
‚îÇ       ‚îú‚îÄ‚îÄ keyword_lab_data.sql         # Business logic in SQL
‚îÇ       ‚îú‚îÄ‚îÄ keyword_lab_count.sql        # Row counting queries
‚îÇ       ‚îú‚îÄ‚îÄ storefront_optimization_*.sql
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ üß† utils/                            # Core system logic
    ‚îú‚îÄ‚îÄ ‚öôÔ∏è input_config.py               # Master configuration hub
    ‚îú‚îÄ‚îÄ üìã page_config.py                # Page & tab definitions  
    ‚îú‚îÄ‚îÄ üé® dynamic_ui.py                 # Automatic UI generation
    ‚îú‚îÄ‚îÄ ‚ö° logic.py                      # Convention-based magic
    ‚îú‚îÄ‚îÄ ‚úÖ input_validator.py            # Validation engine
    ‚îú‚îÄ‚îÄ üîå database.py                   # Connection pool management
    ‚îî‚îÄ‚îÄ üõ†Ô∏è helpers.py                    # Utilities & session state
```

### **Revolutionary Convention-Based Loading**

**Before Optimization:**
```python
# Required manual Python module for each report
data_logic/
‚îú‚îÄ‚îÄ keyword_lab_data.py          # 20 lines of boilerplate
‚îú‚îÄ‚îÄ product_tracking_data.py     # 20 lines of boilerplate  
‚îî‚îÄ‚îÄ campaign_optimization_data.py # 20 lines of boilerplate
```

**After Optimization:**
```python
# Zero Python modules needed - auto-generated at runtime!
data_logic/
‚îî‚îÄ‚îÄ sql/
    ‚îú‚îÄ‚îÄ keyword_lab_data.sql           # Business logic only
    ‚îú‚îÄ‚îÄ keyword_lab_count.sql          # Row counting only
    ‚îî‚îÄ‚îÄ ...                            # Pure SQL, zero boilerplate
```

---

## üöÄ **Quick Start**

### **Prerequisites**
- Python 3.8+
- SingleStore/MySQL database access
- Modern web browser

### **Installation**

1. **Clone the repository**
   ```bash
   git clone https://github.com/your-org/data-export-tool.git
   cd data-export-tool
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment**
   ```bash
   # Create .env file
   cp .env.example .env
   
   # Edit .env with your database credentials:
   DB_HOST=your-database-host
   DB_USER=your-username
   DB_PASSWORD=your-password
   DB_NAME=your-database
   DB_PORT=3306
   ```

5. **Launch the application**
   ```bash
   streamlit run main.py
   ```

6. **Access in browser**
   ```
   http://localhost:8501
   ```

### **First Export in 60 Seconds**

1. üñ±Ô∏è **Select Report**: Choose "Storefront in Workspace" from sidebar
2. üìù **Enter Workspace ID**: Input your workspace identifier  
3. üöÄ **Export**: Click "Get Data" ‚Üí "Export Full Data" ‚Üí Download CSV
4. üéâ **Success**: Clean, formatted data ready for analysis!

---

## üìä **Available Reports**

### **üì± Core Reports**

| Report | Description | Key Use Cases |
|--------|-------------|---------------|
| **üõçÔ∏è Storefront in Workspace** | Directory of all storefronts | Onboarding, storefront discovery |
| **üî¨ Keyword Lab** | Keyword research & discovery | SEO planning, search volume analysis |
| **üìà Keyword Performance** | Advanced keyword analytics | Performance optimization, ROI analysis |
| **üì¶ Product Tracking** | Product positioning & sales | Inventory management, competitive analysis |
| **üèüÔ∏è Competition Landscape** | Market intelligence | Competitive strategy, market share analysis |
| **üéØ Storefront Optimization** | Performance metrics | Revenue optimization, efficiency analysis |
| **ü§ñ Campaign Optimization** | Marketing campaign data | Ad spend optimization, ROAS analysis |

### **üéõÔ∏è Advanced Features**

- **Multi-tab Reports**: Single pages with multiple related datasets
- **Smart Filters**: Device type, display type, product position, date ranges
- **Preset Date Ranges**: Last 30 days, This month, Last month, Custom ranges
- **Dynamic Validation**: Automatic limits based on data size and storefront count
- **Export Previews**: See exactly what you're getting before full export

---

## üõ†Ô∏è **For Developers**

### **Adding New Reports - 3 Simple Steps**

#### **Step 1: Create SQL Files**
```bash
# Create business logic in SQL
touch data_logic/sql/sales_analytics_data.sql
touch data_logic/sql/sales_analytics_count.sql
```

#### **Step 2: Add Configuration**
```python
# utils/input_config.py
"sales_analytics": {
    "name": "Sales Analytics",
    "data_logic_module": "sales_analytics_data",  # Auto-generated!
    "inputs": ["workspace_id", "storefront_ids", "date_range"]
}

# utils/page_config.py  
"6_Sales_Analytics.py": Page(
    title="Sales Analytics", 
    icon="üí∞",
    tabs=[TabPage(title="Sales Analytics", data_source_key='sales_analytics')]
)
```

#### **Step 3: Create Page File**
```python
# pages/6_Sales_Analytics.py
import streamlit as st
from utils.page_config import render_page, PAGES
from utils.helpers import initialize_session_state, display_user_message
import os

initialize_session_state()
display_user_message()

script_name = os.path.basename(__file__)
page_config = PAGES.get(script_name)

if page_config:
    render_page(page_config)
else:
    st.error(f"Page configuration for {script_name} not found.")
```

**üéâ Done!** The system automatically:
- ‚úÖ Generates the Python data module
- ‚úÖ Creates dynamic UI forms
- ‚úÖ Handles validation and error checking
- ‚úÖ Manages database connections
- ‚úÖ Provides caching and optimization

### **Available Input Field Types**

```python
# Reusable field definitions:
"workspace_id"        # Required numeric input
"storefront_ids"      # Comma-separated numeric inputs
"date_range"          # Date range picker with presets
"device_type"         # Dropdown: Mobile|Desktop|None
"display_type"        # Dropdown: Paid|Organic|Top|None  
"product_position"    # Dropdown: -1|4|10|None

# Easy to extend with new field types!
```

### **Convention-Based File Naming**

```bash
# SQL Files (auto-detected):
{data_source_key}_data.sql     # Main business query
{data_source_key}_count.sql    # Row counting query

# Page Files:
{number}_{Title_Case}.py       # Streamlit page

# Examples:
sales_analytics_data.sql       ‚úÖ
sales_analytics_count.sql      ‚úÖ  
6_Sales_Analytics.py          ‚úÖ
```

---

## ‚ö° **Performance & Scalability**

### **Database Connection Optimization**

```python
# Optimized connection pool configuration:
engine = create_engine(
    SQLALCHEMY_DATABASE_URL,
    poolclass=QueuePool,
    pool_size=30,              # 30 base connections
    max_overflow=20,           # +20 overflow = 50 total
    pool_timeout=60,           # 60s timeout for heavy queries
    pool_recycle=1800,         # 30min connection refresh
    pool_pre_ping=True         # Health checks
)
```

**Capacity:** Supports 50+ concurrent users with room for growth

### **3-Layer Caching Strategy**

| Layer | Purpose | TTL | Impact |
|-------|---------|-----|--------|
| **SQL Query Cache** | Database results | 1 hour | 40-100x faster repeated queries |
| **Configuration Cache** | Field definitions | Session | 100x faster UI generation |
| **File Reading Cache** | SQL file content | Session | 4000x faster file access |

### **Smart Query Optimization**

- üîç **Row count checks** before export (prevents server overload)
- üìã **Preview mode** with LIMIT 500 (fast user feedback)
- üöÄ **Full exports** only when needed (optimal resource usage)
- ‚ö†Ô∏è **50k row limit** with helpful suggestions for data reduction

---

## üõ°Ô∏è **Security & Reliability**

### **Security Features**

- üîê **Environment-based credentials** (no secrets in code)
- üõ°Ô∏è **Parameterized queries** (SQL injection prevention)  
- üè¢ **Workspace isolation** (users only see their data)
- üîí **Read-only database access** (no data modification possible)
- ‚úÖ **Input validation** (prevents malformed requests)

### **Error Handling & Recovery**

- üìä **Progressive error messages** with actionable suggestions
- üîÑ **Automatic connection retry** with exponential backoff
- üö® **Graceful degradation** during high load periods
- üìù **Comprehensive logging** for debugging and monitoring
- üõ†Ô∏è **Debug mode** for development troubleshooting

### **Production Readiness**

- ‚ö° **Connection pooling** for optimal database performance
- üìà **Horizontal scaling** ready (stateless design)
- üîç **Health check endpoints** for monitoring
- üìä **Performance metrics** tracking
- üö® **Alert thresholds** for proactive monitoring

---

## üìà **Monitoring & Maintenance**

### **Built-in Health Checks**

```python
# Add to any page for monitoring:
if st.button("üìä System Health"):
    # Database connection pool status
    pool_status = get_pool_status()
    st.metric("Active Connections", f"{pool_status['checked_out']}/{pool_status['size']}")
    
    # Cache performance
    cache_stats = get_cache_statistics()
    st.metric("Cache Hit Ratio", f"{cache_stats['hit_ratio']:.1%}")
    
    # Query performance
    st.metric("Avg Query Time", f"{get_avg_query_time():.2f}s")
```

### **Key Metrics to Monitor**

- üîå **Database connections**: Active vs available
- ‚ö° **Query performance**: Execution times and cache hit ratios  
- üë• **User activity**: Concurrent users and export patterns
- ‚ùå **Error rates**: Failed exports and timeout frequencies
- üíæ **Resource usage**: Memory and CPU utilization

---

## üöß **Development Workflow**

### **Local Development Setup**

```bash
# 1. Environment setup
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 2. Database connection
cp .env.example .env
# Edit .env with local database credentials

# 3. Enable debug mode
export DEBUG_MODE=true

# 4. Run with hot reload
streamlit run main.py --server.runOnSave true
```

### **Testing New Reports**

```bash
# 1. Create SQL files
vim data_logic/sql/test_report_data.sql
vim data_logic/sql/test_report_count.sql

# 2. Add configuration  
vim utils/input_config.py
vim utils/page_config.py

# 3. Create page file
vim pages/99_Test_Report.py

# 4. Test in browser
# Navigate to Test Report page
# Verify form generation, validation, and export
```

### **Debugging Tools**

```python
# Enable debug mode for detailed logging:
st.session_state.debug_mode = True

# View call trace:
display_call_trace()

# Check SQL file detection:
validate_sql_file_detection()

# Monitor database pool:
pool_status = get_pool_status()
```

---

## üéØ **Future Roadmap**

### **Phase 1: Enhanced UX** 
- üìä **Interactive charts** in preview mode
- üîÑ **Real-time export progress** indicators  
- üì± **Mobile-optimized** interface
- üåô **Dark mode** support

### **Phase 2: Advanced Analytics**
- üìà **Automated insights** and anomaly detection
- ü§ñ **AI-powered** query suggestions
- üìä **Custom dashboard** builder
- üîó **API endpoints** for programmatic access

### **Phase 3: Enterprise Features**
- üë• **Role-based access control** 
- üìù **Audit logging** and compliance reporting
- üè¢ **Multi-tenant** support
- ‚òÅÔ∏è **Cloud deployment** options

---

## ü§ù **Contributing**

We welcome contributions! Here's how to get started:

### **Quick Contributions**
- üêõ **Bug reports**: Create issues with detailed reproduction steps
- üí° **Feature requests**: Describe use cases and expected behavior  
- üìö **Documentation**: Improve README, add examples, fix typos
- üß™ **Testing**: Add test cases, report edge cases

### **Development Contributions**

1. **Fork the repository**
2. **Create feature branch**: `git checkout -b feature/amazing-feature`
3. **Follow conventions**: Use existing patterns for consistency
4. **Add tests**: Ensure new code is well-tested
5. **Update docs**: Include relevant documentation updates
6. **Submit pull request**: Clear description of changes and motivation

### **Code Style**
- Follow existing patterns in the codebase
- Use descriptive variable and function names
- Add comments for complex business logic
- Maintain the configuration-driven architecture principles

---

## üìÑ **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## üôè **Acknowledgments**

- **Streamlit Team** for the amazing web app framework
- **SQLAlchemy Team** for robust database abstraction
- **SingleStore Team** for high-performance analytics database
- **Python Community** for the incredible ecosystem

---

## üìû **Support**

### **Getting Help**
- üìñ **Documentation**: Check the built-in Help page in the application
- üêõ **Issues**: Create GitHub issues for bugs and feature requests
- üí¨ **Discussions**: Use GitHub Discussions for questions and ideas
- üìß **Contact**: Reach out to the development team for urgent matters

### **Troubleshooting**

**Common Issues:**

‚ùì **"Database connection timeout"**  
‚Üí Check if database server is accessible and connection pool has capacity

‚ùì **"No data found for selected criteria"**  
‚Üí Verify workspace ID and date range, try broader filters

‚ùì **"Data is too large to export"**  
‚Üí Reduce date range or add more specific filters to get under 50k rows

‚ùì **"Page configuration not found"**  
‚Üí Ensure page file name matches entry in page_config.py

---

## üéâ **Success Stories**

> *"This tool reduced our data export time from hours to minutes. Our analysts can now focus on insights instead of waiting for data!"*  
> ‚Äî **Marketing Analytics Team**

> *"The self-service capability eliminated our SQL bottleneck. Business users love the independence!"*  
> ‚Äî **Business Intelligence Team** 

> *"Adding new reports used to take days of development. Now it's a 30-minute configuration task!"*  
> ‚Äî **Development Team**

---

<div align="center">

### Built with ‚ù§Ô∏è for data-driven teams

**[‚≠ê Star this repository](https://github.com/your-org/data-export-tool)** if it helped your team!

</div>